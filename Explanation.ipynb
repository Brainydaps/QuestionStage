{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Title: Building a Simple NLP Chatbot with Python: A Case Study on \"QuestionStage\"\nIntroduction\nIn this notebook, we'll explore the \"QuestionStage\" project, a Python console application leveraging Natural Language Processing (NLP) techniques to simulate a chatbot. We'll demonstrate how to analyze and respond to user inputs using Python NLP libraries and discuss how these concepts can be applied in a .NET MAUI application using C# NLP toolkits.\n\nTable of Contents\nProject Overview\nSetting Up the Environment\nData Preprocessing\nImplementing NLP Techniques\nTokenization\nPOS Tagging\nLemmatization\nBuilding the Chatbot Logic\nRunning the Chatbot\nTransitioning to .NET MAUI with C#\nConclusion and Next Steps\n1. Project Overview\n\"QuestionStage\" is designed to help users simulate conversation stages typically experienced in online dating or casual interactions. The core functionality revolves around understanding and generating human-like responses to user queries based on predefined responses.","metadata":{}},{"cell_type":"markdown","source":"2. Setting Up the Environment\nWe'll begin by setting up the necessary Python environment. This involves installing libraries such as nltk, textblob, and spacy.","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport subprocess\nimport pkg_resources\n\ndef install(package):\n    try:\n        pkg_resources.get_distribution(package)\n        print(f\"{package} is already installed.\")\n    except pkg_resources.DistributionNotFound:\n        try:\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n            print(f\"Installed {package}.\")\n        except Exception as e:\n            print(f\"Failed to install {package}. Error: {str(e)}\")\n\n# Install necessary packages\npackages = ['nltk', 'textblob', 'spacy']\nfor package in packages:\n    install(package)\n\n# Import installed packages\nimport nltk\nfrom nltk.corpus import wordnet\nfrom textblob import TextBlob\nimport spacy\n\n# Ensure NLTK resources are downloaded with error handling\ndef download_nltk_resource(resource):\n    try:\n        nltk.data.find(resource)\n    except LookupError:\n        nltk.download(resource)\n\ndownload_nltk_resource('wordnet')\ndownload_nltk_resource('averaged_perceptron_tagger')\ndownload_nltk_resource('punkt')\n\n# Ensure spaCy model is downloaded and load it\ntry:\n    nlp = spacy.load('en_core_web_sm')\nexcept OSError:\n    spacy.cli.download('en_core_web_sm')\n    nlp = spacy.load('en_core_web_sm')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Data Preprocessing\nPreprocessing text data is a critical step in any NLP project. We'll demonstrate tokenization, lemmatization, and correction using TextBlob. Note, that preprocess_text() is not a method that exist in the QuestionProcessor.py script itself, just using this method name to demonstrate the logic behind the script.","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    # Correct the question using TextBlob\n    blob = TextBlob(text)\n    corrected_text = str(blob.correct())\n    \n    # Tokenize\n    tokens = nltk.word_tokenize(corrected_text)\n    \n    return corrected_text, tokens\n\ntext = \"Helo! Hw cn I help yu today?\"\ncorrected_text, tokens = preprocess_text(text)\nprint(\"Corrected Text:\", corrected_text)\nprint(\"Tokens:\", tokens)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Implementing NLP Techniques\nPOS Tagging\nPart-of-speech (POS) tagging assigns word types (nouns, verbs, adjectives, etc.) to each token.","metadata":{}},{"cell_type":"code","source":"nltk.download('averaged_perceptron_tagger')\npos_tags = nltk.pos_tag(tokens)\nprint(\"POS Tags:\", pos_tags)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lemmatization\nLemmatization reduces words to their base or root form.","metadata":{}},{"cell_type":"code","source":"lemmatizer = nltk.WordNetLemmatizer()\nlemmas = [lemmatizer.lemmatize(token) for token in tokens]\nprint(\"Lemmas:\", lemmas)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Building the Chatbot Logic\nThe chatbot logic involves responding to user inputs based on a predefined dictionary of responses. The input is processed to identify keywords, and corresponding responses are retrieved.","metadata":{}},{"cell_type":"code","source":"# Define your responses\nresponses = {\n    'name': 'your name',\n    'location': 'your location',\n    'age': 'your age',\n    'occupation': 'your job',\n    'height': 'your height',\n    'physical activity': 'your level of physical actvities',\n    'educational level': 'your educational level',\n    'drinking habit': 'your drinking frequency',\n    'smoking habit': 'your smoking frequency',\n    'gender identity': 'your gender',\n    'seeking': 'what you seek from your partner',\n    'want children': 'if you want children or not',\n    'star sign': 'your horoscope sign',\n    'politics': 'how political are you',\n    'religion': 'your religion or lack of',\n    'tribe': 'your tribe if you have one',\n    'hobbies': 'your hobbies',\n    'passion': 'your passion',\n    'dreams': 'what you dream of doing or being',\n    'expectations in a relationship': 'what you expect in a relationship',\n    'favorite food': 'best food',\n    'favorite color': 'best color',\n    'favorite animal': 'best animal',\n    'favorite movie': 'best movie',\n    'favorite book': 'best book',\n    'favorite music genre': 'best music type',\n    'favorite artist': 'best musician ',\n    'favorite travel destination': 'best place to travel',\n    'favorite sport': 'best sport',\n    'favorite team': 'best team',\n    'favorite player': 'best player',\n    'favorite subject in school': 'best subject',\n    'favorite type of music': 'best music type',\n    'favorite type of food': 'best food type',\n    'favorite type of movie': 'best movie type',\n    'favorite type of book': 'best book type',\n    'favorite type of sport': 'best sport type',\n    'favorite type of travel': 'best travel type',\n    'do you prefer being the one to start chats the most or your man?': 'no',\n}\n\n# Convert the keys in the responses dictionary to lowercase\nresponses = {key.lower(): value for key, value in responses.items()}\n\n# Function to translate Penn Treebank tags to WordNet tags\ndef get_wordnet_pos(treebank_tag):\n    if treebank_tag.startswith('J'):\n        return wordnet.ADJ\n    elif treebank_tag.startswith('V'):\n        return wordnet.VERB\n    elif treebank_tag.startswith('N'):\n        return wordnet.NOUN\n    elif treebank_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return None\n\n# Function to lemmatize verbs to their related noun if possible\ndef verb_to_noun(verb):\n    synsets = wordnet.synsets(verb, pos=wordnet.VERB)\n    for synset in synsets:\n        for lemma in synset.lemmas():\n            if lemma.derivationally_related_forms():\n                for related_lemma in lemma.derivationally_related_forms():\n                    if related_lemma.synset().pos() == 'n':\n                        return related_lemma.name()\n            elif lemma.name().endswith('d'):\n                return lemma.name()[:-1]\n            elif lemma.name().endswith('ed'):\n                return lemma.name()[:-2]\n    return verb\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Running the Chatbot\nThe chatbot runs in a loop, accepting user inputs and providing responses based on the predefined dictionary.","metadata":{}},{"cell_type":"code","source":"while True:\n    question = input(\"Ask me anything: \")\n\n    # Correct the question using TextBlob\n    blob = TextBlob(question)\n    corrected_question = str(blob.correct())\n\n    # Convert the corrected question to lowercase and split it into words\n    keywords = corrected_question.lower().split()\n\n    # List to store matching responses\n    matching_responses = []\n\n    # Tokenize and process the corrected question\n    tokens = nltk.word_tokenize(corrected_question)\n    pos_tags = nltk.pos_tag(tokens)\n\n    for token, pos in pos_tags:\n        wordnet_pos = get_wordnet_pos(pos)\n        if wordnet_pos:\n            lemma = nltk.WordNetLemmatizer().lemmatize(token, pos=wordnet_pos)\n        else:\n            lemma = token\n\n        if wordnet_pos == wordnet.VERB:\n            noun_form = verb_to_noun(lemma)\n            if noun_form in responses:\n                matching_responses.append(responses[noun_form])\n        elif lemma in responses:\n            matching_responses.append(responses[lemma])\n\n    # Prefix matching for additional flexibility\n    for keyword in keywords:\n        keyword_prefix = keyword[:3]\n        for response_key in responses:\n            if response_key.startswith(keyword_prefix):\n                matching_responses.append(responses[response_key])\n                break\n\n    # Process the corrected question with spaCy\n    doc = nlp(corrected_question)\n    for token in doc:\n        lemma = token.lemma_.lower()\n        if lemma in responses:\n            matching_responses.append(responses[lemma])\n\n    # Print all unique responses\n    unique_responses = set(matching_responses)\n    for response in unique_responses:\n        print(response)\n    if not unique_responses:\n        print(\"I don't have an answer for that.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. Transitioning to .NET MAUI with C#\nTo implement similar functionality in a .NET MAUI application, we can use C# NLP libraries/toolkit such as OpenNlp, Catalyst and ML.NET. The concepts remain the same, but the implementation will differ in syntax and library usage. This would be committed to Github under the repo name TalkingStage. \n\n8. Conclusion and Next Steps\nWe've demonstrated how to build a simple NLP chatbot in Python. The next steps involve transitioning.","metadata":{}}]}